{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "# h5py can read hdf5 dataset\n",
    "import h5py\n",
    "\n",
    "# delete bad data files\n",
    "from send2trash import send2trash\n",
    "\n",
    "# fastmri has some k-space undersampling functions we can use\n",
    "# git clone https://github.com/facebookresearch/fastMRI.git\n",
    "# go to the fastmri directory\n",
    "# pip install -e.\n",
    "import fastmri\n",
    "\n",
    "# We will use this functions to generate masks\n",
    "from fastmri.data.subsample import RandomMaskFunc, EquispacedMaskFunc\n",
    "\n",
    "# sigpy is apparently a good MRI viewing tool\n",
    "# pip install sigpy\n",
    "import sigpy as sp\n",
    "import sigpy.plot as pl\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define constants\n",
    "DATASET = 'singlecoil_train'\n",
    "AXES = {\n",
    "        'singlecoil_train' : (1, 2),\n",
    "        'multicoil_train' : (2, 3),\n",
    "       }\n",
    "\n",
    "log = '1'\n",
    "MODEL_NAME = 'model_1'\n",
    "\n",
    "data_path = os.path.join(os.getcwd(), DATASET)\n",
    "mri_paths = glob.glob(os.path.join(data_path, '*1.h5'))\n",
    "log_paths = os.path.join(os.getcwd(), f'logs/{log}.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this block gets Dataset object with imaginary and real separated\n",
    "def _get_kspace_and_reconstruction_rss(filename):\n",
    "    \"\"\"\n",
    "    @params filename: full path to .h5 mri file\n",
    "    @return kspace data of that particular file\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with h5py.File(filename, 'r') as hr:\n",
    "            return hr['kspace'][:], hr['reconstruction_rss'][:]\n",
    "    except:\n",
    "        print(f'Error could not open {filename}')\n",
    "\n",
    "def _get_kspace_undersampled(kspace, center_fractions = [0.04], accelerations = [4]):\n",
    "    \"\"\"\n",
    "    @params kspace: from _get_kspace_and_reconstruction_rss(filename)\n",
    "    @params center_fractions: for undersampling, \n",
    "        N*center_fraction columns in center corresponding to low-frequencies\n",
    "    @params accelerations: how much mri acquisition is sped up\n",
    "    @return undersampled k-space\n",
    "    \"\"\"\n",
    "    mask_func = RandomMaskFunc(\n",
    "        center_fractions = center_fractions, \n",
    "        accelerations = accelerations\n",
    "    )\n",
    "    mask = np.array(mask_func(kspace.shape))\n",
    "    return kspace * mask\n",
    "\n",
    "\n",
    "\n",
    "def _get_mri_im_separated(\n",
    "#     kspace, \n",
    "    reconstruction_rss,\n",
    "    kspace_undersampled, \n",
    "    DATASET\n",
    "):\n",
    "    \"\"\"\n",
    "    separates imaginary from real values\n",
    "    # @params kspace: from _get_kspace_and_reconstruction_rss(filename)\n",
    "    @params reconstruction_rss: reconstructed MR image of fully sampled kspace, provided\n",
    "    @params kspace_undersampled: mask-undersampled k-space from _get_kspace_undersampled\n",
    "    @params DATASET: i.e. 'singlecoil_challenge' or 'multicoil_challenge'\n",
    "    @return (undersampled mri image, fully sampled mri image (i.e. label for GAN))\n",
    "    \"\"\"\n",
    "    undersampled_im = sp.ifft(kspace_undersampled, axes=AXES[DATASET])\n",
    "#     fullysampled_im = sp.ifft(kspace, axes=AXES[DATASET])\n",
    "    \n",
    "    #crop to make sure images are all the size\n",
    "    undersampled_crop = sp.resize(\n",
    "        undersampled_im,\n",
    "        [1, 32, 256, 256]\n",
    "#         [1, 30, 320, 320] # [batch size, height, length, width]\n",
    "    )\n",
    "    \n",
    "    undersampled_crop_real = tf.math.real(undersampled_crop)\n",
    "    undersampled_crop_imag = tf.math.imag(undersampled_crop)\n",
    "    \n",
    "    undersampled_crop = np.stack(\n",
    "        (undersampled_crop_real, undersampled_crop_imag),\n",
    "        axis = 4,\n",
    "    )\n",
    "    \n",
    "    \n",
    "    fullysampled_crop = sp.resize(\n",
    "        reconstruction_rss,\n",
    "        [1, 32, 256, 256]\n",
    "#         [1, 30, 320, 320]\n",
    "    )\n",
    "    \n",
    "    \n",
    "    return (\n",
    "        undersampled_crop,\n",
    "        fullysampled_crop,\n",
    "    )\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def get_datum_from_single_file_separated(filename, DATASET):\n",
    "    \"\"\"\n",
    "    user-facing function for tf Dataset object\n",
    "    @params filename: full path to .h5 mri file\n",
    "    @params DATASET: i.e. 'singlecoil_challenge' or 'multicoil_challenge'\n",
    "    @return (undersampled mri image, fully sampled mri image (i.e. label for GAN))\n",
    "    \"\"\"\n",
    "    kspace, reconstruction_rss = _get_kspace_and_reconstruction_rss(filename)\n",
    "    kspace_undersampled = _get_kspace_undersampled(kspace)\n",
    "    return _get_mri_im_separated(\n",
    "        reconstruction_rss,\n",
    "        kspace_undersampled,\n",
    "        DATASET,\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_data_from_files_separated(filenames, DATASET):  \n",
    "    \"\"\"\n",
    "    user-facing function for tf Dataset object\n",
    "    @params filenames: list of full paths to .h5 mri files\n",
    "    @params DATASET: i.e. 'singlecoil_train' or 'multicoil_train'\n",
    "    @return ndarray of \n",
    "        (undersampled mri image, fully sampled mri image (i.e. label for GAN))\n",
    "    \"\"\"\n",
    "    undersampled_images = np.ones((1, 32, 256, 256, 2)) #[bn, h, l, w, c]\n",
    "    fullysampled_images = np.ones((1, 32, 256, 256))\n",
    "#     undersampled_images = np.ones((1, 30, 320, 320, 2)) #[bn, h, l, w, c]\n",
    "#     fullysampled_images = np.ones((1, 30, 320, 320))\n",
    "    for mri_path in filenames:\n",
    "        try:\n",
    "            # undersampled_crop has real and imag components\n",
    "            undersampled_crop, fullysampled_crop = get_datum_from_single_file_separated(\n",
    "                mri_path, DATASET\n",
    "            )\n",
    "               \n",
    "\n",
    "            undersampled_images = np.vstack(\n",
    "                (undersampled_images, undersampled_crop)\n",
    "            )\n",
    "            \n",
    "            \n",
    "            fullysampled_images = np.vstack(\n",
    "                (fullysampled_images, fullysampled_crop)\n",
    "            )\n",
    "            \n",
    "#             print (f'undersampled image shape: {undersampled_crop.shape}')           \n",
    "#             print (f'undersampled images running total shape: {undersampled_images.shape}')\n",
    "#             print (f'fully sampled images running total shape {fullysampled_images.shape} \\n\\n')\n",
    "\n",
    "            \n",
    "            \n",
    "        except:\n",
    "            print(f'could not open file {mri_path}')\n",
    "#             send2trash(mri_path)\n",
    "            print(f'sent file {mri_path} to trash')\n",
    "    \n",
    "    # reshape with extra one at the end for channel\n",
    "    fullysampled_images = fullysampled_images.reshape(\n",
    "        (-1, 32, 256, 256, 1)\n",
    "    )\n",
    "\n",
    "\n",
    "    return undersampled_images[1:], fullysampled_images[1:]\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "under_sampled_separated, fully_sampled_separated = get_data_from_files_separated(mri_paths, DATASET)\n",
    "ds_separated = tf.data.Dataset.from_tensor_slices((under_sampled_separated, fully_sampled_separated))\n",
    "ds_separated = ds_separated.shuffle(150, seed = 123, reshuffle_each_iteration = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "undersampled size (1, 32, 256, 256, 2) fullysampled size (1, 32, 256, 256, 1)\n",
      "undersampled size (1, 32, 256, 256, 2) fullysampled size (1, 32, 256, 256, 1)\n",
      "undersampled size (1, 32, 256, 256, 2) fullysampled size (1, 32, 256, 256, 1)\n",
      "undersampled size (1, 32, 256, 256, 2) fullysampled size (1, 32, 256, 256, 1)\n",
      "undersampled size (1, 32, 256, 256, 2) fullysampled size (1, 32, 256, 256, 1)\n",
      "undersampled size (1, 32, 256, 256, 2) fullysampled size (1, 32, 256, 256, 1)\n",
      "undersampled size (1, 32, 256, 256, 2) fullysampled size (1, 32, 256, 256, 1)\n",
      "undersampled size (1, 32, 256, 256, 2) fullysampled size (1, 32, 256, 256, 1)\n",
      "undersampled size (1, 32, 256, 256, 2) fullysampled size (1, 32, 256, 256, 1)\n"
     ]
    }
   ],
   "source": [
    "for undersampled_im, fullysampled_im in ds_separated.take(20):\n",
    "    undersampled_im = tf.reshape(undersampled_im, (-1, 32, 256, 256, 2))\n",
    "    fullysampled_im = tf.reshape(fullysampled_im, (-1, 32, 256, 256, 1))\n",
    "    print(f'undersampled size {undersampled_im.shape} fullysampled size {fullysampled_im.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using 1 GPUs\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.models import Model, Input\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Conv3D, Conv3DTranspose\n",
    "from keras.layers import Add, Concatenate\n",
    "from keras.layers import Activation, LeakyReLU\n",
    "from keras.layers import BatchNormalization, Lambda\n",
    "\n",
    "from keras.utils import multi_gpu_model \n",
    "from keras import backend as K\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "devices = device_lib.list_local_devices()\n",
    "gpus = [d for d in devices if d.name.lower().startswith('/device:gpu')]\n",
    "print (f'using {len(gpus)} GPUs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accm(y_true, y_pred):\n",
    "    '''\n",
    "    accuracy metric\n",
    "    '''\n",
    "    y_pred = K.clip(y_pred, -1, 1)\n",
    "    return K.mean(K.equal(y_true, K.round(y_pred)))\n",
    "\n",
    "def mssim(y_true, y_pred):\n",
    "    '''\n",
    "    mean structural similarity index\n",
    "    '''\n",
    "    costs = 1.0 - tf.reduce_mean(tf.image.ssim(y_true, y_pred, 2.0))\n",
    "    return costs\n",
    "\n",
    "def wloss(y_true, y_predict):\n",
    "    '''\n",
    "    Wasserstein loss\n",
    "    '''\n",
    "    return -K.mean(y_true * y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator(\n",
    "    kernel_initz,\n",
    "    inp_shape, # 3d, with channels last\n",
    "    trainable = True,\n",
    "):\n",
    "    \n",
    "    gamma_init = tf.random_normal_initializer(1., 0.02)\n",
    "    \n",
    "    inp = Input(shape = inp_shape) # 3d\n",
    "    \n",
    "    l0 = Conv3D(\n",
    "        filters = 16, kernel_size = 4, strides = (1, 2, 2), \n",
    "        padding = 'same', kernel_initializer = kernel_initz,\n",
    "        )(inp)\n",
    "    l0 = LeakyReLU(alpha = 0.2)(l0)\n",
    "    \n",
    "    \n",
    "    l1 = Conv3D(\n",
    "        filters = 16 * 2, kernel_size = 4, strides = (1, 2, 2), \n",
    "        padding = 'same', kernel_initializer = kernel_initz,\n",
    "        )(l0)\n",
    "    l1 = BatchNormalization(gamma_initializer = gamma_init, trainable = trainable)(l1)\n",
    "    l1 = LeakyReLU(alpha = 0.2)(l1)\n",
    "    \n",
    "    \n",
    "    l2 = Conv3D(\n",
    "        filters = 16 * 4, kernel_size = 4, strides = (1, 2, 2), \n",
    "        padding = 'same', kernel_initializer = kernel_initz,\n",
    "        )(l1)\n",
    "    l2 = BatchNormalization(gamma_initializer = gamma_init, trainable = trainable)(l2)\n",
    "    l2 = LeakyReLU(alpha = 0.2)(l2)\n",
    "    \n",
    "    \n",
    "    l3 = Conv3D(\n",
    "        filters = 16 * 8, kernel_size = 4, strides = (2, 2, 2), \n",
    "        padding = 'same', kernel_initializer = kernel_initz, \n",
    "        )(l2)\n",
    "    l3 = BatchNormalization(gamma_initializer = gamma_init, trainable = trainable)(l3)\n",
    "    l3 = LeakyReLU(alpha = 0.2)(l3)\n",
    "    \n",
    "    \n",
    "    l4 = Conv3D(\n",
    "        filters = 16 * 16, kernel_size = 4, strides = (2, 2, 2),\n",
    "        padding = 'same', kernel_initializer = kernel_initz,\n",
    "        )(l3)\n",
    "    l4 = BatchNormalization(gamma_initializer = gamma_init, trainable = trainable)(l4)\n",
    "    l4 = LeakyReLU(alpha = 0.2)(l4)\n",
    "    \n",
    "    \n",
    "    l7 = Conv3D(\n",
    "        filters = 16 * 8, kernel_size = 1, strides = (1, 1, 1),\n",
    "        padding = 'same', kernel_initializer = kernel_initz,\n",
    "        )(l4)\n",
    "    l7 = BatchNormalization(gamma_initializer = gamma_init, trainable = trainable)(l7)\n",
    "    l7 = LeakyReLU(alpha = 0.2)(l7)\n",
    "    \n",
    "    \n",
    "    l8 = Conv3D(\n",
    "        filters = 16 * 4, kernel_size = 1, strides = (1, 1, 1), \n",
    "        padding = 'same', kernel_initializer = kernel_initz,\n",
    "        )(l7)\n",
    "    l8 = BatchNormalization(gamma_initializer = gamma_init, trainable = trainable)(l8)\n",
    "    l8 = LeakyReLU(alpha = 0.2)(l8)\n",
    "    \n",
    "    \n",
    "    l9 = Conv3D(\n",
    "        filters = 16 * 2, kernel_size = 3, strides = (1, 1, 1),\n",
    "        padding = 'same', kernel_initializer = kernel_initz,\n",
    "        )(l8)\n",
    "    l9 = BatchNormalization(gamma_initializer = gamma_init, trainable = trainable)(l9)\n",
    "    l9 = LeakyReLU(alpha = 0.2)(l9)\n",
    "    \n",
    "    \n",
    "    l10 = Conv3D(\n",
    "        filters = 16 * 8, kernel_size = 3, strides = (1, 1, 1),\n",
    "        padding = 'same', kernel_initializer = kernel_initz,\n",
    "        )(l9)\n",
    "    l10 = BatchNormalization(gamma_initializer = gamma_init, trainable = trainable)(l10)\n",
    "    l10 = LeakyReLU(alpha = 0.2)(l10)\n",
    "    \n",
    "    \n",
    "    l11 = Add()([l7,l10])\n",
    "    l11 = LeakyReLU(alpha = 0.2)(l11)\n",
    "    \n",
    "    \n",
    "    out = Conv3D(\n",
    "        filters = 1, kernel_size = 3, strides = 1,\n",
    "        padding = 'same', kernel_initializer = 'he_normal',\n",
    "        )(l11)\n",
    "    \n",
    "    \n",
    "    model = Model(inputs = inp, outputs = out)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resden(\n",
    "    x, fil_lay, fil_end, beta, \n",
    "    gamma_init, kernel_initz, trainable,\n",
    "):   \n",
    "    \n",
    "    x1 = Conv3D(\n",
    "        filters = fil_lay, kernel_size = 3, strides = 1,\n",
    "        padding = 'same', kernel_initializer = kernel_initz,\n",
    "        )(x)\n",
    "    x1 = BatchNormalization(gamma_initializer = gamma_init, trainable = trainable)(x1)\n",
    "    x1 = LeakyReLU(alpha = 0.2)(x1)\n",
    "    x1=Concatenate(axis=-1)([x, x1])\n",
    "    \n",
    "    \n",
    "    x2 = Conv3D(\n",
    "        filters = fil_lay, kernel_size = 3, strides = 1,\n",
    "        padding = 'same', kernel_initializer = kernel_initz,\n",
    "        )(x1)\n",
    "    x2 = BatchNormalization(gamma_initializer = gamma_init, trainable = trainable)(x2)\n",
    "    x2 = LeakyReLU(alpha = 0.2)(x2)\n",
    "    x2 = Concatenate(axis = -1)([x1, x2])\n",
    "     \n",
    "        \n",
    "    x3 = Conv3D(\n",
    "        filters = fil_lay, kernel_size = 3, strides = 1,\n",
    "        padding = 'same', kernel_initializer = kernel_initz, \n",
    "        )(x2)\n",
    "    x3 = BatchNormalization(gamma_initializer = gamma_init, trainable = trainable)(x3)\n",
    "    x3 = LeakyReLU(alpha = 0.2)(x3)\n",
    "    x3 = Concatenate(axis = -1)([x2, x3])\n",
    "    \n",
    "    \n",
    "#     x4 = Conv3D(\n",
    "#         filters = fil_lay, kernel_size = 3, strides = 1,\n",
    "#         padding = 'same', kernel_initializer = kernel_initz, \n",
    "#         )(x3)\n",
    "#     x4 = BatchNormalization(gamma_initializer = gamma_init, trainable = trainable)(x4)\n",
    "#     x4 = LeakyReLU(alpha = 0.2)(x4)\n",
    "#     x4 = Concatenate(axis = -1)([x3, x4])\n",
    "    \n",
    "    \n",
    "    x5 = Conv3D(\n",
    "        filters = fil_end, kernel_size = 3, strides = 1,\n",
    "        padding = 'same', kernel_initializer = kernel_initz,\n",
    "        )(x3)\n",
    "    \n",
    "    x5 = Lambda(lambda x: x * beta)(x5)\n",
    "    \n",
    "    xout = Add()([x5,x])\n",
    "    return xout\n",
    "\n",
    "def resresden(x, fil_lay, fil_end, beta, gamma_init, kernel_initz, trainable):\n",
    "    \n",
    "    x1 = resden(x,  fil_lay, fil_end, beta, gamma_init, kernel_initz, trainable,)\n",
    "#     x2 = resden(x1, fil_lay, fil_end, beta, gamma_init, kernel_initz, trainable,)\n",
    "    x3 = resden(x, fil_lay, fil_end, beta, gamma_init, kernel_initz, trainable,)\n",
    "    \n",
    "    x3 = Lambda(lambda x : x * beta)(x3)\n",
    "    \n",
    "    xout = Add()([x3,x])\n",
    "    return xout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(inp_shape, kernel_initz, trainable = True,):\n",
    "    gamma_init = tf.random_normal_initializer(1., 0.02)\n",
    "    \n",
    "    fil_lay = 32\n",
    "    fil_end = 512\n",
    "    rrd_count = 12\n",
    "    beta = 0.2\n",
    "\n",
    "    \n",
    "    inp_usamp_imag = Input(inp_shape) # (-1, 32, 256, 256, 2)\n",
    "    \n",
    "    \n",
    "    lay_1dn = Conv3D(\n",
    "        filters = 32, kernel_size = 4, strides = (1, 2, 2), # 32, 128, 128\n",
    "        padding = 'same', kernel_initializer = kernel_initz,\n",
    "        )(inp_usamp_imag)\n",
    "    lay_1dn = LeakyReLU(alpha = 0.2)(lay_1dn)\n",
    "\n",
    "    \n",
    "    lay_2dn = Conv3D(\n",
    "        filters = 64, kernel_size = 4, strides = (1, 2, 2), # 32, 64, 64\n",
    "        padding = 'same', kernel_initializer = kernel_initz,\n",
    "        )(lay_1dn)\n",
    "    lay_2dn = BatchNormalization(gamma_initializer = gamma_init, trainable = trainable)(lay_2dn)\n",
    "    lay_2dn = LeakyReLU(alpha = 0.2)(lay_2dn)\n",
    "\n",
    "    \n",
    "    lay_3dn = Conv3D(\n",
    "        filters = 128, kernel_size = 4, strides = (1, 2, 2), # 32, 32, 32\n",
    "        padding = 'same', kernel_initializer = kernel_initz,\n",
    "        )(lay_2dn)\n",
    "    lay_3dn = BatchNormalization(gamma_initializer = gamma_init, trainable = trainable)(lay_3dn)\n",
    "    lay_3dn = LeakyReLU(alpha = 0.2)(lay_3dn)\n",
    "\n",
    "    \n",
    "    lay_4dn = Conv3D(\n",
    "        filters = 256, kernel_size = 4, strides = (2, 2, 2), # 16, 16, 16\n",
    "        padding = 'same', kernel_initializer = kernel_initz, \n",
    "        )(lay_3dn)\n",
    "    lay_4dn = BatchNormalization(gamma_initializer = gamma_init, trainable = trainable)(lay_4dn)\n",
    "    lay_4dn = LeakyReLU(alpha = 0.2)(lay_4dn)  \n",
    "\n",
    "    \n",
    "    lay_5dn = Conv3D(\n",
    "        filters = 256, kernel_size = 4, strides = (2, 2, 2), # 8, 8, 8\n",
    "        padding = 'same', kernel_initializer = kernel_initz,\n",
    "        )(lay_4dn)\n",
    "    lay_5dn = BatchNormalization(gamma_initializer = gamma_init, trainable = trainable)(lay_5dn)\n",
    "    lay_5dn = LeakyReLU(alpha = 0.2)(lay_5dn)\n",
    "\n",
    "\n",
    "    c1 = Conv3D(\n",
    "        filters = fil_end, kernel_size = 3, strides = 1,\n",
    "        padding = 'same', kernel_initializer = kernel_initz, \n",
    "        )(lay_5dn)\n",
    "    \n",
    "    xrrd = c1\n",
    "    for _ in range(rrd_count):\n",
    "        xrrd = resresden(xrrd, fil_lay, fil_end, beta, gamma_init, kernel_initz, trainable)\n",
    "\n",
    "    c2 = Conv3D(\n",
    "        filters = fil_end, kernel_size = 3, strides = 1,\n",
    "        padding = 'same', kernel_initializer = kernel_initz, \n",
    "        )(xrrd)\n",
    "    \n",
    "    \n",
    "    lay_5upc = Add()([c1, c2]) # 8, 8, 8\n",
    "\n",
    "    \n",
    "    lay_4up = Conv3DTranspose(\n",
    "        filters = 256, kernel_size = 4, strides = (2, 2, 2), # 16, 16, 16\n",
    "        padding = 'same', kernel_initializer = kernel_initz,\n",
    "        )(lay_5upc)\n",
    "    lay_4up = BatchNormalization(gamma_initializer = gamma_init, trainable = trainable)(lay_4up)\n",
    "    lay_4up = Activation('relu')(lay_4up) \n",
    "\n",
    "    lay_4upc = Concatenate(axis = -1)([lay_4up,lay_4dn]) \n",
    "\n",
    "    \n",
    "    \n",
    "    lay_3up = Conv3DTranspose(\n",
    "        filters = 128, kernel_size = 4, strides = (2, 2, 2), # 32, 32, 32\n",
    "        padding = 'same', kernel_initializer = kernel_initz,\n",
    "        )(lay_4upc) \n",
    "    lay_3up = BatchNormalization(gamma_initializer = gamma_init, trainable = trainable)(lay_3up)\n",
    "    lay_3up = Activation('relu')(lay_3up)\n",
    "\n",
    "    lay_3upc = Concatenate(axis = -1)([lay_3up,lay_3dn])\n",
    "\n",
    "    \n",
    "    lay_2up = Conv3DTranspose(\n",
    "        filters = 64, kernel_size = 4, strides = (1, 2, 2), #32, 64, 64\n",
    "        padding = 'same', kernel_initializer = kernel_initz,\n",
    "        )(lay_3upc)\n",
    "    lay_2up = BatchNormalization(gamma_initializer = gamma_init, trainable = trainable)(lay_2up)\n",
    "    lay_2up = Activation('relu')(lay_2up)\n",
    "\n",
    "    lay_2upc = Concatenate(axis = -1)([lay_2up, lay_2dn])\n",
    "\n",
    "    \n",
    "    lay_1up = Conv3DTranspose(\n",
    "        filters = 32, kernel_size = 4, strides = (1, 2, 2), #32, 128, 128\n",
    "        padding = 'same', kernel_initializer = kernel_initz,\n",
    "        )(lay_2upc)\n",
    "    lay_1up = BatchNormalization(gamma_initializer = gamma_init, trainable = trainable)(lay_1up)\n",
    "    lay_1up = Activation('relu')(lay_1up) \n",
    "\n",
    "    lay_1upc = Concatenate(axis = -1)([lay_1up,lay_1dn])\n",
    "\n",
    "    lay_256up = Conv3DTranspose(\n",
    "        filters = 32, kernel_size = 4, strides = (1, 2, 2), #32, 256, 256\n",
    "        padding = 'same', kernel_initializer = kernel_initz,\n",
    "        )(lay_1upc)\n",
    "    lay_256up = BatchNormalization(gamma_initializer = gamma_init, trainable = trainable)(lay_256up)\n",
    "    lay_256up = Activation('relu')(lay_256up)\n",
    "\n",
    "    out = Conv3D(\n",
    "        filters = 1, kernel_size = 1, strides = (1, 1, 1), activation = 'tanh', \n",
    "        padding = 'same', kernel_initializer = kernel_initz,\n",
    "        )(lay_256up)\n",
    "\n",
    "    model = Model(inputs = inp_usamp_imag, outputs = out)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_gan_model(gen_model, dis_model, inp_shape):\n",
    "        \n",
    "    dis_model.trainable = False\n",
    "    inp = Input(shape = inp_shape)\n",
    "    out_g = gen_model(inp)\n",
    "    out_dis = dis_model(out_g)\n",
    "    model = Model(inputs = inp, outputs = [out_dis, out_g])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    g_model, d_model, gan_model, \n",
    "    dataset, \n",
    "    n_epochs, n_batch, n_critic, \n",
    "    clip_val, n_patch, \n",
    "    f,\n",
    "):\n",
    "    \n",
    "    bat_per_epo = int(np.ceil(tf.data.experimental.cardinality(dataset).numpy() / n_batch))\n",
    "    half_batch = int(np.ceil(n_batch / 2))\n",
    "    \n",
    "    for i in range(n_epochs):\n",
    "        for j in range(bat_per_epo):\n",
    "            \n",
    "            # training the discriminator\n",
    "            for k in range(n_critic):\n",
    "                X = np.ones((1, 32, 256, 256, 1)) #[h, l, w, c]\n",
    "                y = np.ones((1, n_patch, n_patch, n_patch, 1))\n",
    "\n",
    "                for usamp_data, fsamp_data in dataset.take(half_batch):\n",
    "                    usamp_data = tf.reshape(usamp_data, (-1, 32, 256, 256, 2))\n",
    "                    fsamp_data = tf.reshape(fsamp_data, (-1, 32, 256, 256, 1))\n",
    "                    \n",
    "#                     print(f'usamp shape: {usamp_data.shape}, fsamp shape: {fsamp_data.shape}')\n",
    "                    \n",
    "                    X_real = fsamp_data\n",
    "                    X_fake = g_model.predict(usamp_data)\n",
    "                    \n",
    "                    y_real = np.ones((1, n_patch, n_patch, n_patch, 1))\n",
    "                    y_fake = -np.ones((1, n_patch, n_patch, n_patch, 1))\n",
    "\n",
    "                    X, y = np.vstack((X, X_real)), np.vstack((y, y_real))\n",
    "                    X, y = np.vstack((X, X_fake)), np.vstack((y, y_fake))\n",
    "                    \n",
    "                    \n",
    "\n",
    "                X, y = X[1:], y[1:] # take out first np.ones\n",
    "                \n",
    "#                 print(f'X shape: {X.shape}, y shape: {y.shape}')\n",
    "                d_loss, accuracy = d_model.train_on_batch(X, y)\n",
    "\n",
    "                for l in d_model.layers:\n",
    "                    weights = l.get_weights()\n",
    "                    weights = [np.clip(w, -clip_val, clip_val) for w in weights]\n",
    "                    l.set_weights(weights)\n",
    "\n",
    "                    \n",
    "            # training the generator\n",
    "            X_usamps = np.ones((1, 32, 256, 256, 2)) #[h, l, w, c]\n",
    "            X_fsamps = np.ones((1, 32, 256, 256, 1))\n",
    "\n",
    "            for X_usamp, X_fsamp in dataset.take(n_batch):\n",
    "                \n",
    "                X_usamp = tf.reshape(X_usamp, (-1, 32, 256, 256, 2))\n",
    "                X_fsamp = tf.reshape(X_fsamp, (-1, 32, 256, 256, 1))\n",
    "\n",
    "                X_usamps = np.vstack((X_usamps, X_usamp))\n",
    "                X_fsamps = np.vstack((X_fsamps, X_fsamp))\n",
    "                \n",
    "            X_usamps, X_fsamps = X_usamps[1:], X_fsamps[1:] # take out first np.ones\n",
    "            y_gan = np.ones((n_batch, n_patch, n_patch, n_patch, 1))\n",
    "            g_loss = gan_model.train_on_batch ([X_usamps], [y_gan, X_fsamps])\n",
    "            \n",
    "            \n",
    "#             f.write(f'>epoch: {i+1}, batch: {(j+1)/bat_per_epo}, discriminator loss: {d_loss}, acc: {accuracy},  wasserstein: {g_loss[1]},  mae: {g_loss[2]},  mssim: {g_loss[3]}, generator_loss: {g_loss[0]}')\n",
    "            \n",
    "            f.write(f'''>epoch: {i+1}, batch: {np.round((j+1)/bat_per_epo, 6)} \\n''')\n",
    "            f.write(f'''    discriminator loss: {np.round(d_loss, 6)}, generator loss: {np.round(g_loss[0], 6)}, acc: {np.round(accuracy, 6)} \\n\\n\\n''')        \n",
    "    \n",
    "\n",
    "            print (f'''>epoch: {i+1}, batch: {(j+1)/bat_per_epo}''')\n",
    "            print(f'''    discriminator loss: {d_loss}, generator loss: {g_loss[0]}, acc: {accuracy} \\n\\n''')    \n",
    "        \n",
    "        filename = f'{MODEL_NAME}_epoch_{i+1}.h5'\n",
    "        g_model.save(filename)\n",
    "        \n",
    "    f.close() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 32, 256, 256, 2)] 0         \n",
      "_________________________________________________________________\n",
      "model_1 (Model)              (None, 32, 256, 256, 1)   149392001 \n",
      "_________________________________________________________________\n",
      "model (Model)                (None, 8, 8, 8, 1)        3000785   \n",
      "=================================================================\n",
      "Total params: 152,392,786\n",
      "Trainable params: 149,387,265\n",
      "Non-trainable params: 3,005,521\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "\n",
    "# hyperparameters       \n",
    "n_epochs = 1\n",
    "n_batch = 1\n",
    "n_critic = 1\n",
    "clip_val = 0.05\n",
    "in_shape_gen = (32, 256, 256, 2)\n",
    "in_shape_dis = (32, 256, 256, 1)\n",
    "\n",
    "\n",
    "# multiple GPUs (doesn't work, kernel crashes)\n",
    "# strategy = tf.distribute.MirroredStrategy()\n",
    "# print(\"Number of devices: {}\".format(strategy.num_replicas_in_sync))\n",
    "\n",
    "# with strategy.scope():\n",
    "#     d_model = discriminator(inp_shape = in_shape_dis, kernel_initz = 'he_normal', trainable = True)\n",
    "#     d_model = multi_gpu_model(d_model, gpus = 2, cpu_relocation = True)\n",
    "#     opt = Adam(lr = 0.0002, beta_1 = 0.5)\n",
    "#     d_model.compile(loss = wloss, optimizer = opt, metrics = [accm])\n",
    "#     # d_model.summary()\n",
    "\n",
    "\n",
    "#     g_model = generator(inp_shape = in_shape_gen, kernel_initz = 'he_normal', trainable = True)\n",
    "#     g_model = multi_gpu_model(g_model, gpus = 2, cpu_relocation = True)\n",
    "\n",
    "\n",
    "#     gan_model = define_gan_model(g_model, d_model, in_shape_gen)\n",
    "#     opt1 = Adam(lr = 0.0001, beta_1 = 0.5)\n",
    "#     gan_model.compile(loss = [wloss, 'mae', mssim], optimizer = opt1, loss_weights = [0.01, 20.0, 1.0])\n",
    "#     # g_model.summary()\n",
    "\n",
    "\n",
    "\n",
    "d_model = discriminator(inp_shape = in_shape_dis, kernel_initz = 'he_normal', trainable = True)\n",
    "opt = Adam(lr = 0.0002, beta_1 = 0.5)\n",
    "d_model.compile(loss = wloss, optimizer = opt, metrics = [accm])\n",
    "# d_model.summary()\n",
    "\n",
    "\n",
    "g_model = generator(inp_shape = in_shape_gen, kernel_initz = 'he_normal', trainable = True)\n",
    "\n",
    "gan_model = define_gan_model(g_model, d_model, in_shape_gen)\n",
    "opt1 = Adam(lr = 0.0001, beta_1 = 0.5)\n",
    "gan_model.compile(loss = [wloss, 'mae', mssim], optimizer = opt1, loss_weights = [0.01, 20.0, 1.0])\n",
    "# g_model.summary()\n",
    "\n",
    "\n",
    "# other paramters\n",
    "n_patch = d_model.output_shape[1]\n",
    "f = open(log_paths, 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">epoch: 1, batch: 0.1111111111111111\n",
      "    discriminator loss: 0.03282199427485466, generator loss: 15.623870849609375, acc: 0.29296875 \n",
      "\n",
      "\n",
      ">epoch: 1, batch: 0.2222222222222222\n",
      "    discriminator loss: -0.008487838320434093, generator loss: 14.36258602142334, acc: 0.0 \n",
      "\n",
      "\n",
      ">epoch: 1, batch: 0.3333333333333333\n",
      "    discriminator loss: -0.020223159343004227, generator loss: 10.282111167907715, acc: 0.0 \n",
      "\n",
      "\n",
      ">epoch: 1, batch: 0.4444444444444444\n",
      "    discriminator loss: -0.02248506061732769, generator loss: 6.822440147399902, acc: 0.0 \n",
      "\n",
      "\n",
      ">epoch: 1, batch: 0.5555555555555556\n",
      "    discriminator loss: -0.03181546926498413, generator loss: 5.372978687286377, acc: 0.0 \n",
      "\n",
      "\n",
      ">epoch: 1, batch: 0.6666666666666666\n",
      "    discriminator loss: -0.04207652062177658, generator loss: 4.410793304443359, acc: 0.0 \n",
      "\n",
      "\n",
      ">epoch: 1, batch: 0.7777777777777778\n",
      "    discriminator loss: -0.05107714980840683, generator loss: 3.803701877593994, acc: 0.0 \n",
      "\n",
      "\n",
      ">epoch: 1, batch: 0.8888888888888888\n",
      "    discriminator loss: -0.06052131578326225, generator loss: 3.9832189083099365, acc: 0.0 \n",
      "\n",
      "\n",
      ">epoch: 1, batch: 1.0\n",
      "    discriminator loss: -0.06858892738819122, generator loss: 3.7917444705963135, acc: 0.0 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train(\n",
    "    g_model, d_model, gan_model, \n",
    "    ds_separated, \n",
    "    n_epochs, n_batch, n_critic, \n",
    "    clip_val, n_patch, \n",
    "    f\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "“bebi205gpu”",
   "language": "python",
   "name": "bebi205gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
