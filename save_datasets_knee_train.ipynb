{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "npz file for each MRI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import re\n",
    "\n",
    "# h5py can read hdf5 dataset\n",
    "import h5py\n",
    "\n",
    "# delete bad data files\n",
    "from send2trash import send2trash\n",
    "\n",
    "# fastmri has some k-space undersampling functions we can use\n",
    "# git clone https://github.com/facebookresearch/fastMRI.git\n",
    "# go to the fastmri directory\n",
    "# pip install -e .\n",
    "import fastmri\n",
    "\n",
    "# We will use this functions to generate masks\n",
    "from fastmri.data.subsample import RandomMaskFunc, EquispacedMaskFunc\n",
    "\n",
    "# sigpy is apparently a good MRI viewing tool\n",
    "# pip install sigpy\n",
    "import sigpy as sp\n",
    "import sigpy.plot as pl\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bye\n"
     ]
    }
   ],
   "source": [
    "# define paths\n",
    "\n",
    "# # master\n",
    "DATASETS = [\n",
    "    'singlecoil_train',\n",
    "#     'singlecoil_val',\n",
    "#     'singlecoil_test_v2'\n",
    "]\n",
    "\n",
    "# purely for testing / demo-ing master\n",
    "data_save_path = os.path.join('/central/groups/BEBi_205_Spring_2021/vliu', 'dataset_objects')\n",
    "\n",
    "AXES = {\n",
    "        'singlecoil_train' : (1, 2),\n",
    "        'singlecoil_val' : (1, 2),\n",
    "        'singlecoil_test_v2' : (1, 2),\n",
    "       }\n",
    "\n",
    "\n",
    "# # single dataset, for debugging / demo purposes. cwd is home directory\n",
    "# DATASET = 'singlecoil_val' #singlecoil_val, singlecoil_test_v2\n",
    "# data_path = os.path.join('/central/groups/BEBi_205_Spring_2021/vliu', DATASET)\n",
    "# mri_paths = glob.glob(os.path.join(data_path, '*99.h5'))\n",
    "# data_save_path = os.path.join('/central/groups/BEBi_205_Spring_2021/vliu/dataset_objects', DATASET) \n",
    "print ('bye')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this block gets Dataset object with imaginary and real separated\n",
    "def _get_kspace_and_reconstruction_rss(filename, DATASET):\n",
    "    \"\"\"\n",
    "    @params filename: full path to .h5 mri file\n",
    "    @return kspace data of that particular file\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with h5py.File(filename, 'r') as hr:\n",
    "            return hr['kspace'][:], hr['reconstruction_rss'][:]\n",
    "    except:\n",
    "        print(f'Error could not open {filename}')\n",
    "\n",
    "def _get_kspace_undersampled(kspace, center_fractions = [0.04], accelerations = [4]):\n",
    "    \"\"\"\n",
    "    @params kspace: from _get_kspace_and_reconstruction_rss(filename, DATASET)\n",
    "    @params center_fractions: for undersampling, \n",
    "        Ncenter_fraction columns in center corresponding to low-frequencies\n",
    "    @params accelerations: how much mri acquisition is sped up\n",
    "    @return undersampled k-space\n",
    "    \"\"\"\n",
    "    mask_func = RandomMaskFunc(\n",
    "        center_fractions = center_fractions, \n",
    "        accelerations = accelerations\n",
    "    )\n",
    "    mask = np.array(mask_func(kspace.shape))\n",
    "    return kspace * mask\n",
    "\n",
    "\n",
    "\n",
    "def _get_mri_im_separated(\n",
    "    reconstruction_rss,\n",
    "    kspace_undersampled, \n",
    "    DATASET\n",
    "):\n",
    "    \"\"\"\n",
    "    separates imaginary from real values\n",
    "    # @params kspace: from _get_kspace_and_reconstruction_rss(filename)\n",
    "    @params reconstruction_rss: reconstructed MR image of fully sampled kspace, provided\n",
    "    @params kspace_undersampled: mask-undersampled k-space from _get_kspace_undersampled\n",
    "    @params DATASET: i.e. 'singlecoil_challenge' or 'multicoil_challenge'\n",
    "    @return (undersampled mri image, fully sampled mri image (i.e. label for GAN))\n",
    "    \"\"\"\n",
    "    undersampled_im = sp.ifft(kspace_undersampled, axes = AXES[DATASET])\n",
    "    \n",
    "    #crop to make sure images are all the size\n",
    "    undersampled_crop = sp.resize(\n",
    "        undersampled_im,\n",
    "        [1, 32, 256, 256]\n",
    "    )\n",
    "    \n",
    "    undersampled_crop_real = tf.math.real(undersampled_crop)\n",
    "    undersampled_crop_imag = tf.math.imag(undersampled_crop)\n",
    "    \n",
    "    undersampled_crop = np.stack(\n",
    "        (undersampled_crop_real, undersampled_crop_imag),\n",
    "        axis = 4,\n",
    "    )\n",
    "    \n",
    "    \n",
    "    fullysampled_crop = sp.resize(\n",
    "        reconstruction_rss,\n",
    "        [1, 32, 256, 256]\n",
    "    )\n",
    "    \n",
    "    return (\n",
    "        undersampled_crop,\n",
    "        fullysampled_crop,\n",
    "    )\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def get_datum_from_single_file_separated(filename, DATASET):\n",
    "    \"\"\"\n",
    "    user-facing function for tf Dataset object\n",
    "    @params filename: full path to .h5 mri file\n",
    "    @params DATASET: i.e. 'singlecoil_challenge' or 'multicoil_challenge'\n",
    "    @return (undersampled mri image, fully sampled mri image (i.e. label for GAN))\n",
    "    \"\"\"\n",
    "    kspace, reconstruction_rss = _get_kspace_and_reconstruction_rss(filename, DATASET)\n",
    "    kspace_undersampled = _get_kspace_undersampled(kspace)\n",
    "    return _get_mri_im_separated(\n",
    "        reconstruction_rss,\n",
    "        kspace_undersampled,\n",
    "        DATASET,\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def save_data(filenames, DATASET):  \n",
    "    \"\"\"\n",
    "    user-facing function to save each MRI as\n",
    "    undersampled / ground truth pair as npz\n",
    "    @params filenames: list of full paths to .h5 mri files\n",
    "    @params DATASET: i.e. 'singlecoil_train' or 'multicoil_train'\n",
    "    @return True if saved successfully\n",
    "    \"\"\"\n",
    "    print_marker = 1\n",
    "    \n",
    "    # regex for getting mri_file names\n",
    "    pattern = f'{DATASET}/(.*)'\n",
    "    regex = re.compile(pattern)\n",
    "    \n",
    "    for i, mri_path in enumerate(filenames):\n",
    "        try:\n",
    "            # undersampled_crop has real and imag components\n",
    "            undersampled_crop, fullysampled_crop = get_datum_from_single_file_separated(\n",
    "                mri_path, DATASET\n",
    "            )\n",
    "            \n",
    "            # reshape for channels and imaginary / real numbers\n",
    "            undersampled_crop = undersampled_crop.reshape(-1, 32, 256, 256, 2)\n",
    "            fullysampled_crop = fullysampled_crop.reshape(-1, 32, 256, 256, 1)\n",
    "            \n",
    "            \n",
    "            # save\n",
    "            mri_filename = regex.findall(mri_path)[0]\n",
    "            data_save_file = os.path.join(data_save_path, f'{DATASET}/{mri_filename}.npz')\n",
    "#             if os.path.isfile(data_save_file):\n",
    "#                 os.remove(data_save_file)\n",
    "            np.savez(data_save_file, undersampled_crop, fullysampled_crop)\n",
    "            \n",
    "            # print progress\n",
    "            print_marker += 1\n",
    "            if print_marker % 50 == 0:\n",
    "                print(f'undersampled and saved {print_marker} {DATASET} files thus far')\n",
    "            \n",
    "            \n",
    "        except:\n",
    "            print(f'could not process file {mri_path}')\n",
    "#             send2trash(mri_path)\n",
    "            print(f'sent file {mri_path} to trash')\n",
    "    \n",
    "    print (f'check out files at {data_save_path}/{DATASET}/ directory')\n",
    "\n",
    "    return True\n",
    "\n",
    "#\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def master():\n",
    "    '''\n",
    "    main program to execute save_data for all datasets\n",
    "    including train, val, and test\n",
    "    '''\n",
    "    for DATASET in DATASETS:\n",
    "        print (f'> > > processing {DATASET} images')\n",
    "        # define paths\n",
    "        data_path = os.path.join(\n",
    "            '/central/groups/BEBi_205_Spring_2021/vliu', \n",
    "            DATASET\n",
    "        )\n",
    "        mri_paths = glob.glob(os.path.join(data_path, '*.h5'))\n",
    "\n",
    "        save_data(mri_paths, DATASET) \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> > > processing singlecoil_train images\n",
      "undersampled and saved 50 singlecoil_train files thus far\n",
      "undersampled and saved 100 singlecoil_train files thus far\n",
      "undersampled and saved 150 singlecoil_train files thus far\n",
      "undersampled and saved 200 singlecoil_train files thus far\n",
      "undersampled and saved 250 singlecoil_train files thus far\n",
      "undersampled and saved 300 singlecoil_train files thus far\n",
      "undersampled and saved 350 singlecoil_train files thus far\n",
      "undersampled and saved 400 singlecoil_train files thus far\n",
      "undersampled and saved 450 singlecoil_train files thus far\n",
      "undersampled and saved 500 singlecoil_train files thus far\n",
      "undersampled and saved 550 singlecoil_train files thus far\n",
      "undersampled and saved 600 singlecoil_train files thus far\n",
      "undersampled and saved 650 singlecoil_train files thus far\n",
      "undersampled and saved 700 singlecoil_train files thus far\n",
      "undersampled and saved 750 singlecoil_train files thus far\n",
      "undersampled and saved 800 singlecoil_train files thus far\n",
      "undersampled and saved 850 singlecoil_train files thus far\n",
      "undersampled and saved 900 singlecoil_train files thus far\n",
      "check out files at /central/groups/BEBi_205_Spring_2021/vliu/dataset_objects/singlecoil_train/ directory\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "master()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "npzfile = np.load(f'{data_save_path}.npz')\n",
    "under_sampled_separated = npzfile['arr_0']\n",
    "fully_sampled_separated = npzfile['arr_1']\n",
    "\n",
    "# ds_separated = tf.data.Dataset.from_tensor_slices((under_sampled_separated, fully_sampled_separated))\n",
    "# ds_separated = ds_separated.shuffle(1000, seed = 123, reshuffle_each_iteration = True)\n",
    "\n",
    "# # check Dataset object was created properly\n",
    "# ds_separated = ds_separated.shuffle(1000)\n",
    "# for undersampled_im, fullysampled_im in ds_separated.take(10):\n",
    "#     undersampled_im = tf.reshape(undersampled_im, (-1, 32, 256, 256, 2))\n",
    "#     fullysampled_im = tf.reshape(fullysampled_im, (-1, 32, 256, 256, 1))\n",
    "#     print(f'undersampled size {undersampled_im.shape} fullysampled size {fullysampled_im.shape}')\n",
    "    \n",
    "\n",
    "# for undersampled_im, fullysampled_im in ds_separated.take(1):\n",
    "#     pl.ImagePlot(undersampled_im[:, :, :, 0]) #this is just real numbers. Don't use this in comparison\n",
    "#     pl.ImagePlot(fullysampled_im[:, :, :, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 32, 256, 256, 2)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "under_sampled_separated.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (bebi205)",
   "language": "python",
   "name": "bebi205"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
