{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "# h5py can read hdf5 dataset\n",
    "import h5py\n",
    "\n",
    "# delete bad data files\n",
    "from send2trash import send2trash\n",
    "\n",
    "# fastmri has some k-space undersampling functions we can use\n",
    "# git clone https://github.com/facebookresearch/fastMRI.git\n",
    "# go to the fastmri directory\n",
    "# pip install -e.\n",
    "import fastmri\n",
    "\n",
    "# We will use this functions to generate masks\n",
    "from fastmri.data.subsample import RandomMaskFunc, EquispacedMaskFunc\n",
    "\n",
    "# sigpy is apparently a good MRI viewing tool\n",
    "# pip install sigpy\n",
    "import sigpy as sp\n",
    "import sigpy.plot as pl\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define constants\n",
    "DATASET = 'singlecoil_train'\n",
    "AXES = {\n",
    "        'singlecoil_train' : (1, 2),\n",
    "        'multicoil_train' : (2, 3),\n",
    "       }\n",
    "PATH = os.path.join(os.path.dirname(os.getcwd()), DATASET)\n",
    "mri_paths = glob.glob(os.path.join(PATH, '*.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_kspace_and_reconstruction_rss(filename):\n",
    "    \"\"\"\n",
    "    @params filename: full path to .h5 mri file\n",
    "    @return kspace data of that particular file\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with h5py.File(filename, 'r') as hr:\n",
    "            return hr['kspace'][:], hr['reconstruction_rss'][:]\n",
    "    except:\n",
    "        print(f'Error could not open {filename}')\n",
    "\n",
    "def _get_kspace_undersampled(kspace, center_fractions = [0.04], accelerations = [4]):\n",
    "    \"\"\"\n",
    "    @params kspace: from _get_kspace_and_reconstruction_rss(filename)\n",
    "    @params center_fractions: for undersampling, \n",
    "        N*center_fraction columns in center corresponding to low-frequencies\n",
    "    @params accelerations: how much mri acquisition is sped up\n",
    "    @return undersampled k-space\n",
    "    \"\"\"\n",
    "    mask_func = RandomMaskFunc(\n",
    "        center_fractions = center_fractions, \n",
    "        accelerations = accelerations\n",
    "    )\n",
    "    mask = np.array(mask_func(kspace.shape))\n",
    "    return kspace * mask\n",
    "\n",
    "def _get_mri_im(\n",
    "#     kspace, \n",
    "    reconstruction_rss,\n",
    "    kspace_undersampled, \n",
    "    DATASET\n",
    "):\n",
    "    \"\"\"\n",
    "    # @params kspace: from _get_kspace_and_reconstruction_rss(filename)\n",
    "    @params reconstruction_rss: reconstructed MR image of fully sampled kspace, provided\n",
    "    @params kspace_undersampled: mask-undersampled k-space from _get_kspace_undersampled\n",
    "    @params DATASET: i.e. 'singlecoil_challenge' or 'multicoil_challenge'\n",
    "    @return (undersampled mri image, fully sampled mri image (i.e. label for GAN))\n",
    "    \"\"\"\n",
    "    undersampled_im = sp.ifft(kspace_undersampled, axes=AXES[DATASET])\n",
    "#     fullysampled_im = sp.ifft(kspace, axes=AXES[DATASET])\n",
    "    \n",
    "    #crop to make sure images are all the same size\n",
    "    undersampled_crop = sp.resize(\n",
    "        undersampled_im,\n",
    "        [1, 30, 320, 320]\n",
    "    )\n",
    "    \n",
    "    fullysampled_crop = sp.resize(\n",
    "        reconstruction_rss,\n",
    "        [1, 30, 320, 320]\n",
    "    )\n",
    "    \n",
    "    \n",
    "    return (\n",
    "        undersampled_crop,\n",
    "        fullysampled_crop,\n",
    "    )\n",
    "    \n",
    "\n",
    "def get_datum_from_single_file(filename, DATASET):\n",
    "    \"\"\"\n",
    "    user-facing function for tf Dataset object\n",
    "    @params filename: full path to .h5 mri file\n",
    "    @params DATASET: i.e. 'singlecoil_challenge' or 'multicoil_challenge'\n",
    "    @return (undersampled mri image, fully sampled mri image (i.e. label for GAN))\n",
    "    \"\"\"\n",
    "    kspace, reconstruction_rss = _get_kspace_and_reconstruction_rss(filename)\n",
    "    kspace_undersampled = _get_kspace_undersampled(kspace)\n",
    "    return _get_mri_im(\n",
    "        reconstruction_rss,\n",
    "        kspace_undersampled,\n",
    "        DATASET,\n",
    "    )\n",
    "\n",
    "\n",
    "def get_data_from_files(filenames, DATASET):  \n",
    "    \"\"\"\n",
    "    user-facing function for tf Dataset object\n",
    "    @params filenames: list of full paths to .h5 mri files\n",
    "    @params DATASET: i.e. 'singlecoil_train' or 'multicoil_train'\n",
    "    @return ndarray of \n",
    "        (undersampled mri image, fully sampled mri image (i.e. label for GAN))\n",
    "    \"\"\"\n",
    "    undersampled_images = np.ones((1, 30, 320, 320))\n",
    "    fullysampled_images = np.ones((1, 30, 320, 320))\n",
    "    for mri_path in filenames:\n",
    "        try:\n",
    "            undersampled_crop, fullysampled_crop = get_datum_from_single_file(\n",
    "                mri_path, DATASET\n",
    "            )\n",
    "            undersampled_images = np.vstack(\n",
    "                (undersampled_images, undersampled_crop)\n",
    "            )\n",
    "            fullysampled_images = np.vstack(\n",
    "                (fullysampled_images, fullysampled_crop)\n",
    "            )\n",
    "        except:\n",
    "            print(f'could not open file {mri_path}')\n",
    "            send2trash(mri_path)\n",
    "            print(f'sent file {mri_path} to trash')\n",
    "            \n",
    "    return undersampled_images[1:], fullysampled_images[1:]\n",
    "\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TakeDataset shapes: ((30, 320, 320), (30, 320, 320)), types: (tf.float64, tf.float64)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "undersampled, fully_sampled = get_data_from_files(mri_paths, DATASET)\n",
    "ds = tf.data.Dataset.from_tensor_slices((undersampled, fully_sampled))\n",
    "ds = ds.shuffle(150,seed=123,reshuffle_each_iteration=True)\n",
    "ds.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for undersampled_im, fullysampled_im in ds.take(1):\n",
    "    pl.ImagePlot(undersampled_im)\n",
    "    pl.ImagePlot(fullysampled_im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a really nice comparison of what the partially sampled k-space (top) fully sampled k-space (bottom) will do to the reconstruction of the MR image. \n",
    "\n",
    "\n",
    "Normally for MRI, there is not much preprocessing beyond what has already been done. I could not find a golden standard with which to augment the dataset, but I may consult my SURF mentor in the coming days for more information. This is likely due to the fact that MRIs are already so rich with information, and improper augmentation may cause the GAN to hallucinate. In this particular project, we potentially have access to thousands of MRIs (the limitation is the disk quota, not the dataset itself), so I will go to OH this week to discuss how we may deal with this issue. While it may not be practical to store thousands of MRIs on the Caltech Clusters, I would imagine that it would be theoretically preferable to leverage the large dataset, rather than augment the current dataset.\n",
    "\n",
    "\n",
    "Some more statistics: currently, we have $100$ MRIs in the dataset. I think it is interesting to note that there are other datasets availble from NYU fastMRI as well. Mainly, they also have multicoil knee, DICOM knee, multicoil brain, and DICOM brain datasets, each of which have hundreds of MR images as well. Based on how the disc space works out, it might be interesting to see if we can train the GAN to simulate super-resolution and deblurring for multiple types of MRIs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bibliography\n",
    "Will be in better format once we're off JupyterNotebook\n",
    "\n",
    "Bustin, A., Fuin, N., Botnar, R. M., & Prieto, C. (2020). From Compressed-Sensing to Artificial Intelligence-Based Cardiac MRI Reconstruction. Frontiers in Cardiovascular Medicine, 7. https://doi.org/10.3389/fcvm.2020.00017\n",
    "\n",
    "\n",
    "F. Knoll et al., \"fastMRI: A publicly available raw K-space and DICOM dataset of knee images for accelerated MR image reconstruction using machine learning\", Radiol.: Artif. Intell., vol. 2, no. 1, 2020.\n",
    "\n",
    "Ye, J.C. Compressed sensing MRI: a review from signal processing perspective. BMC biomed eng 1, 8 (2019). https://doi.org/10.1186/s42490-019-0006-z\n",
    "\n",
    "Zbontar J, Knoll F, Sriram A, et al. fastMRI: An Open Dataset and Bench- â€¨",
    "marks for Accelerated MRI. arXiv [cs.CV]. http://arxiv.org/abs/1811.08839. Published 2018. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (bebi205)",
   "language": "python",
   "name": "bebi205"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
